{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Modos de como usar o Leitor de Arquivos\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Como usar o downloader com apenas um link:\n",
    "Vamos usar como exemplo os dados do [COVID do RS](https://ti.saude.rs.gov.br/covid19/). "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import utils\n",
    "\n",
    "# declarando variáveis:\n",
    "path = os.getcwd() # identifica o diretório em que está sendo executado\n",
    "destino = path + '/arquivos/'\n",
    "download_link = 'https://ti.saude.rs.gov.br/covid19/download'\n",
    "arquivos_covid = destino\n",
    "\n",
    "# download dos arquivos:\n",
    "utils.downloader(download_link,destino,lista=False)"
   ]
  },
  {
   "source": [
    "## Como usar o downloader com um arquivo de links\n",
    "Vamos usar como exemplo os dados de estabelecimentos dos [dados abertos de empresas](https://www.gov.br/receitafederal/pt-br/assuntos/orientacao-tributaria/cadastros/consultas/dados-publicos-cnpj). Para isso, vamos usar o arquivo `estabelecimentoss_rf_urls.txt` que contem uma lista de URLs para os arquivos de estabelecimentos."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "/Users/frederico/leitor-arquivos/estabelecimentos_rf_urls.txt\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import utils\n",
    "\n",
    "# fazendo o download dos arquivos:\n",
    "utils.downloader(download_link='/estabelecimentos_rf_urls.txt',destino='/arquivos/', lista=True)"
   ]
  },
  {
   "source": [
    "## Descompactando os arquivos\n",
    "Agora vamos descompactar os arquivos do diretorio `/arquivos/` para dentro do diretório `/arquivos/unzipped/`."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'arquivos descompactados com sucesso'"
      ]
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "source": [
    "import os\n",
    "import utils\n",
    "\n",
    "# descompactando os arquivos:\n",
    "utils.descompactando(caminho_do_arquivo='/arquivos/', tipo_arquivo='zip', destino=os.getcwd()+'/arquivos/unzipped/')"
   ]
  },
  {
   "source": [
    "## Como usar o leitor dos dados em spark\n",
    "\n",
    "Para fazer o processamento de dados, pode-se usar a linguagem [SQL para Spark](https://spark.apache.org/docs/latest/sql-ref-syntax.html). As consultas devem ser salvas com o formato `nome.sql` na pasta de consultas.  \n",
    "Vamos executar a `consulta_exemplo_1.sql` na base de dados do covid (schema já definido) conforme abaixo. O resultado da consulta será salvo em CSV dentro da pasta `/arquivos_processados/`."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "serao lidos 7 arquivos\n",
      "consulta_exemplo_1.sql\n",
      "consulta_exemplo_2.sql\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'foram processados 2'"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "import os\n",
    "import leitor\n",
    "\n",
    "path = os.getcwd() # identifica o diretório em que está sendo executado\n",
    "\n",
    "# processando os arquivos\n",
    "leitor.processamento_sql_spark(\n",
    "    pasta_de_consultas=path+'/consultas/', \n",
    "    destino=path+'/arquivos_processados/', \n",
    "    diretorio=path+'/arquivos/',\n",
    "    separador=';',\n",
    "    sql_alias='covid_rs')"
   ]
  },
  {
   "source": [
    "Agora vamos executar consultas similares na base de estabelecimentos da Receita Federal, uma base de dados que precisa ter seu schema definido. Para isso, primeido vamos determinar o schema e depois executar a consulta passando o schema definido previamente."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "serao lidos 10 arquivos\nconsulta_exemplo_1.sql\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'foram processados 1'"
      ]
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "source": [
    "import os\n",
    "import leitor\n",
    "from pyspark.sql.types import StringType, StructField, StructType # para determinar o schema\n",
    "\n",
    "# declarando o schema\n",
    "schema_estabelecimentos = StructType([\n",
    "        StructField('cnpj_basico',StringType(),True),\n",
    "        StructField('cnpj_ordem',StringType(),True),\n",
    "        StructField('cnpj_dv',StringType(),True),\n",
    "        StructField('identificador_matriz_filial',StringType(),True),\n",
    "        StructField('nome_fantasia',StringType(),True),\n",
    "        StructField('situacao_cadastral',StringType(),True),\n",
    "        StructField('data_situacao_cadastral',StringType(),True),\n",
    "        StructField('motivo_situacao_cadastral',StringType(),True),\n",
    "        StructField('nome_da_cidade_no_exterior',StringType(),True),\n",
    "        StructField('pais',StringType(),True),\n",
    "        StructField('data_inicio_atividade',StringType(),True),\n",
    "        StructField('cnae_fiscal_principal',StringType(),True),\n",
    "        StructField('cnae_fiscal_secundaria',StringType(),True),\n",
    "        StructField('tipo_logradouro',StringType(),True),\n",
    "        StructField('logradouro',StringType(),True),\n",
    "        StructField('numero',StringType(),True),\n",
    "        StructField('complemento',StringType(),True),\n",
    "        StructField('bairro',StringType(),True),\n",
    "        StructField('cep',StringType(),True),\n",
    "        StructField('uf',StringType(),True),\n",
    "        StructField('municipio',StringType(),True),\n",
    "        StructField('ddd_1',StringType(),True),\n",
    "        StructField('telefone_1',StringType(),True),\n",
    "        StructField('ddd_2',StringType(),True),\n",
    "        StructField('telefone_2',StringType(),True),\n",
    "        StructField('ddd_fax',StringType(),True),\n",
    "        StructField('fax',StringType(),True),\n",
    "        StructField('correio_eletronico',StringType(),True),\n",
    "        StructField('situacao_especial',StringType(),True),\n",
    "        StructField('data_situacao_especial',StringType(),True)\n",
    "        ])\n",
    "\n",
    "path = os.getcwd() # identifica o diretório em que está sendo executado\n",
    "\n",
    "# processando os arquivos\n",
    "leitor.processamento_sql_spark(\n",
    "    pasta_de_consultas=path+'/consultas/', \n",
    "    destino=path+'/arquivos_processados/', \n",
    "    diretorio=path+'/arquivos/unzipped/',\n",
    "    separador=';',\n",
    "    schema=schema_estabelecimentos,\n",
    "    sql_alias='estabelecimentos')\n"
   ]
  },
  {
   "source": [
    "**FIM! :D**"
   ],
   "cell_type": "markdown",
   "metadata": {}
  }
 ]
}